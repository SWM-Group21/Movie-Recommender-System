# -*- coding: utf-8 -*-
"""hugging_face_recommendation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1b1L6OeVtR5xwHPZ7nsn-f-YQVsfbM9Rw
"""

import pandas as pd
import numpy as np
from transformers import BertModel, BertTokenizer
import torch
from sklearn.metrics.pairwise import cosine_similarity

# Load MovieLens 20M dataset (replace 'path_to_dataset' with your actual path)
#/Users/herambhshah/Downloads/archive
data_path = 'rating.csv'
movies_path = 'movie.csv'

ratings = pd.read_csv(data_path)
movies = pd.read_csv(movies_path)

# Merge ratings with movie titles
movie_ratings = pd.merge(ratings, movies[['movieId', 'title']], on='movieId')

# Group ratings by movie and calculate average rating
average_ratings = movie_ratings.groupby('title')['rating'].mean().reset_index()

# Filter out movies with low ratings
threshold_rating = 4.0
high_rated_movies = average_ratings[average_ratings['rating'] >= threshold_rating]

# Select a subset of high-rated movies for embedding
num_movies_to_embed = 100
selected_movies = high_rated_movies.sample(n=num_movies_to_embed, random_state=42)

selected_movies = selected_movies.reset_index(drop=True)

# Load pre-trained BERT model and tokenizer
model_name = "bert-base-uncased"
tokenizer = BertTokenizer.from_pretrained(model_name)
model = BertModel.from_pretrained(model_name)

# Tokenize and obtain embeddings for selected movies
tokenized_inputs = tokenizer(selected_movies['title'].tolist(), return_tensors="pt", padding=True, truncation=True)
with torch.no_grad():
    outputs = model(**tokenized_inputs)

# Extract embeddings for [CLS] token
movie_embeddings = np.array(outputs.last_hidden_state[:, 0, :])

def recommend_movies(query_embedding, embeddings, movie_titles, top_n=3):

    # Add checks for array lengths
    # if len(embeddings) != len(movie_titles):
    #     raise ValueError("Lengths of embeddings and movie_titles must be the same")

    # # Check for NaN or missing values in query_embedding
    # if np.isnan(query_embedding).any():
    #     raise ValueError("query_embedding contains NaN values")

    # Calculate cosine similarity
    similarities = cosine_similarity([query_embedding], embeddings)[0]

    # # Add check for valid indices
    # if len(similarities) < top_n:
    #     raise ValueError(f"Top {top_n} requested, but only {len(similarities)} available.")

    # Add check for valid indices
    if len(similarities) < top_n:
        top_n = len(similarities)
        print(f"Top {top_n} requested, but only {top_n} available.")

    # Get recommended indices
    recommended_indices = similarities.argsort()[-top_n:][::-1]
    # for i in recommended_indices:
    #   print(movie_titles[i]['title'])
    # return
    # # Create list of recommended movies with their similarities
    recommended_movies = [(movie_titles[i], similarities[i]) for i in recommended_indices]
    return recommended_movies



# Get user input for movie preferences
user_input = input("Enter a list of movie titles separated by commas: ")
user_movie_titles = [title.strip().lower() for title in user_input.split(',')]

# # Tokenize and obtain embeddings for all movies in the dataset
# tokenized_inputs_all = tokenizer(average_ratings['title'].tolist(), return_tensors="pt", padding=True, truncation=True)
# with torch.no_grad():
#     outputs_all = model(**tokenized_inputs_all)

# # Extract embeddings for [CLS] token for all movies
# all_movie_embeddings = np.array(outputs_all.last_hidden_state[:, 0, :])

# Tokenize and obtain embeddings for user-selected movies
tokenized_inputs_user = tokenizer(user_movie_titles, return_tensors="pt", padding=True, truncation=True)
with torch.no_grad():
    outputs_user = model(**tokenized_inputs_user)

# Extract embeddings for [CLS] token for user-selected movies
user_embeddings = np.array(outputs_user.last_hidden_state[:, 0, :])

# Combine user embeddings (average) to represent user preferences
user_query_embedding = np.mean(user_embeddings, axis=0)


# Get movie recommendations
recommendations = recommend_movies(user_query_embedding, movie_embeddings, selected_movies['title'])

# Display recommendations
print("Movie Recommendations:")
for movie, similarity in recommendations:
    print(f"{movie} (Similarity: {similarity:.2f})")



print("User Input Titles:", user_movie_titles)
print("MovieLens Titles:", average_ratings['title'].tolist())

average_ratings

# #-----------------Not completed
# # Extract movieIds from recommendations
# recommended_movie_ids = [average_ratings[average_ratings['title'] == movie]['movieId'].values[0] for movie, _ in recommendations]


# #------------------------ Evaluation metrics
# # Calculate Precision at K (P@K)
# K = 5  # top K recommendations
# relevant_movies = user_ratings_df[user_ratings_df['movieId'].isin(recommended_movie_ids)]['movieId'].tolist()
# precision_at_K = len(set(relevant_movies).intersection(set(recommended_movie_ids))) / K

# print(f"Precision at {K}: {precision_at_K:.2f}")